# Hito 4: Composici√≥n de Servicios üó∞Ô∏è

### Versi√≥n 1.4

Este documento corresponde al **Hito 4** del proyecto de **gesti√≥n de pe√±as y ligas individuales deportivas**. Durante este hito, se ha avanzado significativamente en la configuraci√≥n, prueba y depuraci√≥n de la infraestructura basada en contenedores para soportar la aplicaci√≥n. Este proceso implic√≥ ajustes iterativos para lograr una arquitectura funcional, escalable y que gestione adecuadamente los registros de logs.

---

## üóã 1. Documentaci√≥n y Justificaci√≥n de la Estructura del Cl√∫ster de Contenedores

Se definieron cinco servicios principales que conforman la aplicaci√≥n y permiten su correcta ejecuci√≥n:

### **App (Contenedor de Aplicaci√≥n)**

- **Descripci√≥n**: Ejecuta la l√≥gica de la aplicaci√≥n desarrollada en Flask.
- **Responsabilidad**: Gestiona las peticiones HTTP y realiza consultas a la base de datos.
- **Cambios Implementados**:
  - Se realiz√≥ una migraci√≥n completa de SQLite a PostgreSQL, lo que implic√≥ modificar todas las consultas debido a diferencias de sintaxis entre ambas bases de datos.
  - Se incorpor√≥ la biblioteca `psycopg2` para establecer la conexi√≥n con PostgreSQL.
  - Se implement√≥ el uso de variables de entorno para configurar el acceso a la base de datos de manera din√°mica.
- **Pruebas realizadas**:
  - Se verific√≥ que todas las consultas modificadas fueran compatibles con PostgreSQL.
  - Se realizaron pruebas de estr√©s para confirmar la estabilidad y el manejo de concurrencia en la base de datos.

### **DB (Contenedor de Base de Datos)**

- **Descripci√≥n**: Implementado con PostgreSQL para el almacenamiento de informaci√≥n estructurada.
- **Cambios Implementados**:
  - Se configur√≥ un script inicial para la creaci√≥n y poblaci√≥n de tablas.
  - La conexi√≥n a la base de datos ahora se realiza mediante un endpoint configurable a trav√©s de variables de entorno.
  - Se realizaron pruebas exhaustivas para garantizar la compatibilidad de las consultas y la integridad de los datos migrados desde SQLite.
- **Pruebas realizadas**:
  - Validaci√≥n de integridad de datos tras la migraci√≥n.
  - Simulaci√≥n de fallos en el contenedor para verificar la recuperaci√≥n mediante vol√∫menes persistentes.

### **Grafana (Contenedor de Monitorizaci√≥n)**

- **Descripci√≥n**: Proporciona un entorno visual para analizar m√©tricas y logs.
- **Justificaci√≥n**:
  - Se eligi√≥ Grafana por su capacidad de integraci√≥n con m√∫ltiples fuentes de datos, incluidas Loki y Promtail.
  - Su interfaz amigable facilita el monitoreo en tiempo real.

### **Loki (Contenedor de Logs)**

- **Descripci√≥n**: Centraliza la recolecci√≥n de logs enviados por la aplicaci√≥n y otros servicios.
- **Justificaci√≥n**:
  - Loki se seleccion√≥ por su dise√±o ligero y su perfecta integraci√≥n con Grafana.
  - Su configuraci√≥n simple permiti√≥ reducir la complejidad respecto a otras soluciones como ELK.

### **Promtail (Agente de Logs)**

- **Descripci√≥n**: Recolecta logs locales y los env√≠a a Loki para su almacenamiento y an√°lisis.
- **Justificaci√≥n**:
  - Promtail fue elegido por ser un agente oficial de Loki, asegurando compatibilidad nativa y menor esfuerzo de configuraci√≥n.
- **Pruebas realizadas**:
  - Validaci√≥n de recolecci√≥n de logs desde el contenedor de aplicaci√≥n.
  - Simulaci√≥n de grandes vol√∫menes de logs para medir el rendimiento.

Esta configuraci√≥n se desarroll√≥ iterativamente, abordando problemas t√©cnicos relacionados con permisos, conectividad de red y compatibilidad entre versiones.

---

## üóã 2. Documentaci√≥n y Justificaci√≥n de la Configuraci√≥n de los Contenedores

He optado por esta configuraci√≥n tras explorar otras alternativas como la **pila ELK** y **Graylog**, las cuales presentaron m√∫ltiples problemas en la configuraci√≥n de vol√∫menes y permisos de autenticaci√≥n, haciendo inviable su implementaci√≥n. A continuaci√≥n, se detalla la justificaci√≥n de la configuraci√≥n seleccionada y una comparaci√≥n con las alternativas consideradas.

### 2.1. Pila ELK

La **pila ELK** es un conjunto de herramientas de c√≥digo abierto desarrollado por Elastic, utilizado para la b√∫squeda, an√°lisis y visualizaci√≥n de datos en tiempo real. Es especialmente popular para la gesti√≥n de registros (logs) y el monitoreo de sistemas.

**Componentes Principales de ELK:**
![pila ELK](/docs/images/ELK.png)

#### Elasticsearch
- **Descripci√≥n:**
  - Motor de b√∫squeda y an√°lisis de datos basado en Lucene.
  - Almacena datos en formato estructurado (documentos JSON) y permite realizar b√∫squedas r√°pidas, agregaciones y an√°lisis complejos.
  - Act√∫a como el n√∫cleo de la pila, donde se almacenan los datos enviados por los otros componentes.

#### Logstash
- **Descripci√≥n:**
  - Herramienta de procesamiento y recolecci√≥n de datos.
  - Recibe logs o datos de diversas fuentes, los transforma si es necesario y los env√≠a a Elasticsearch para su almacenamiento.
  - Ofrece gran flexibilidad gracias a su sistema de plugins, permitiendo conectar m√∫ltiples fuentes de datos (archivos, bases de datos, etc.) y realizar transformaciones como filtrado, enmascarado y enriquecimiento.

#### Kibana
- **Descripci√≥n:**
  - Herramienta de visualizaci√≥n y an√°lisis de datos.
  - Proporciona una interfaz gr√°fica para consultar y analizar los datos almacenados en Elasticsearch.
  - Permite crear dashboards personalizados, gr√°ficos interactivos y visualizaciones en tiempo real.

**Problemas Encontrados con ELK:**
- Configuraci√≥n compleja de vol√∫menes y permisos de autenticaci√≥n.
- Dificultades para mantener la estabilidad del sistema, lo que llev√≥ a fallos frecuentes durante la implementaci√≥n.

### 2.2. Graylog

**Graylog** act√∫a como una soluci√≥n centralizada de gesti√≥n de logs dentro de la infraestructura de contenedores. A continuaci√≥n, se explica c√≥mo funciona cada componente y c√≥mo interact√∫an:
![Graylog](/docs/images/Graylog.png)
#### Componentes de la Configuraci√≥n

##### Graylog (graylog-container)
- **Descripci√≥n:** N√∫cleo de la soluci√≥n de logs.
- **Funciones:**
  - Recibe, almacena y permite consultar logs en tiempo real desde las aplicaciones y servicios configurados.
  - Proporciona una interfaz web accesible en [`http://localhost:9000`](http://localhost:9000) para buscar y analizar los logs.
- **Variables de Entorno Clave:**
  - `GRAYLOG_HTTP_EXTERNAL_URI`: URI para la interfaz externa de Graylog.
  - `GRAYLOG_ROOT_PASSWORD_SHA2`: Hash SHA256 de la contrase√±a del usuario root.
  - `GRAYLOG_PASSWORD_SECRET`: Cadena base64 que Graylog utiliza para la encriptaci√≥n de contrase√±as.

##### MongoDB (mongo-container)
- **Descripci√≥n:** Base de datos utilizada por Graylog.
- **Funciones:**
  - Almacena configuraciones, metadatos y otra informaci√≥n no relacionada con los logs.
  - Requisito imprescindible para el funcionamiento de Graylog.

##### Elasticsearch (elasticsearch-container)
- **Descripci√≥n:** Motor de b√∫squeda y almacenamiento de logs para Graylog.
- **Configuraci√≥n:**
  - Configurado como un nodo √∫nico con los siguientes par√°metros:
    - `discovery.type=single-node`: Indica que Elasticsearch funciona como una instancia independiente.
    - `ES_JAVA_OPTS=-Xms512m -Xmx512m`: Limita el uso de memoria de Elasticsearch a 512 MB.

##### Aplicaci√≥n (app-container)
- **Descripci√≥n:** Fuente principal de los logs que Graylog procesar√°.
- **Funciones:**
  - Los logs generados en `./logs` pueden ser enviados a Graylog a trav√©s de entradas configuradas (por ejemplo, GELF, Syslog, etc.).

##### PostgreSQL (db-container)
- **Descripci√≥n:** Base de datos de la aplicaci√≥n.
- **Funciones:**
  - No interact√∫a directamente con Graylog, pero almacena toda la informaci√≥n estructurada requerida por la aplicaci√≥n.

#### Flujo de Trabajo de Graylog

1. **Recolecci√≥n de Logs:**
   - Graylog recibe logs desde la aplicaci√≥n o cualquier otra fuente configurada.
   - **Protocolos soportados:** GELF (Graylog Extended Log Format), Syslog, JSON, entre otros.
   - Los logs pueden ser enviados directamente desde la aplicaci√≥n o mediante agentes intermedios (como Filebeat o Fluentd).

2. **Procesamiento y Almacenamiento:**
   - Los logs se procesan en Graylog y se almacenan en Elasticsearch para su posterior consulta.
   - Los mensajes son indexados para facilitar b√∫squedas r√°pidas y eficientes.

3. **Interfaz Web:**
   - Graylog expone una interfaz web en [`http://localhost:9000`](http://localhost:9000) para buscar, analizar y visualizar los logs.
   - Permite filtrar por campos, realizar b√∫squedas espec√≠ficas y generar alertas basadas en los datos recibidos.

4. **Configuraci√≥n y Gesti√≥n:**
   - MongoDB almacena informaci√≥n de configuraciones, usuarios y dashboards creados en Graylog.
   - La interfaz de Graylog permite configurar entradas (inputs), salidas (outputs) y pipelines para manipular los logs.

Aqu√≠ muestro un ejemplo de los contenedores de Graylog desplegados pero observamos como antes comentaba que pese a estar desplegados cuando 
intentamos acceder a los permisos no reconoce ni al usuario admin ni su contrase√±a. Pese a probar diferentes versioens del contenedor fue en vano. 
De todas formas se mantiene en el proyecto algunos archivos por si en el futuro se quisiera hacer una comparaci√≥n.
![Contenedores Graylog](/docs/images/4.png)
![Fallo Graylog](/docs/images/6.png)
### 2.3. Configuraci√≥n de los Contenedores

A continuaci√≥n, se describen los contenedores utilizados en la configuraci√≥n seleccionada, sus im√°genes base, configuraciones esenciales y responsabilidades principales.

#### 2.3.1. App (Contenedor de Aplicaci√≥n)

- **Base de Imagen:** `python:3.12-slim`
  - Imagen ligera, segura y adecuada para ejecutar aplicaciones modernas basadas en Python.
- **Configuraci√≥n Esencial:**
  - Uso de variables de entorno para configurar la conexi√≥n a la base de datos y garantizar portabilidad.
  - Montaje del c√≥digo fuente y los logs como vol√∫menes para facilitar el desarrollo y la depuraci√≥n.
- **Responsabilidad Principal:** Proveer la l√≥gica de negocio y los endpoints de la API REST.

#### 2.3.2. DB (Contenedor de Base de Datos)

- **Base de Imagen:** `postgres:15`
  - PostgreSQL es una base de datos confiable y ampliamente utilizada para aplicaciones empresariales.
- **Configuraci√≥n Esencial:**
  - Uso de vol√∫menes para persistir datos entre reinicios.
  - Inclusi√≥n de un script inicial (`Gestion_Penas.sql`) para configurar tablas y datos iniciales.
- **Responsabilidad Principal:** Almacenar toda la informaci√≥n estructurada requerida por la aplicaci√≥n.

#### 2.3.3. Grafana (Monitorizaci√≥n)

- **Base de Imagen:** `grafana/grafana-oss`
  - Herramienta de visualizaci√≥n de m√©tricas y logs altamente personalizable.
- **Configuraci√≥n Esencial:**
  - Conexi√≥n directa con Loki como fuente de datos para mostrar logs en tiempo real.
- **Responsabilidad Principal:** Ofrecer un panel visual para analizar datos de logs y m√©tricas.

#### 2.3.4. Loki (Sistema de Logs)

- **Base de Imagen:** `grafana/loki:2.9.0`
  - Soluci√≥n ligera y eficiente para gestionar logs centralizados.
- **Configuraci√≥n Esencial:**
  - Uso de un archivo de configuraci√≥n personalizado para especificar el formato y almacenamiento de logs.
- **Responsabilidad Principal:** Almacenar logs recolectados por Promtail y servirlos a Grafana.

#### 2.3.5. Promtail (Agente de Logs)

- **Base de Imagen:** `grafana/promtail:2.9.0`
  - Agente encargado de recolectar y enviar logs a Loki.
- **Configuraci√≥n Esencial:**
  - Uso de un archivo de configuraci√≥n personalizado para definir las fuentes y etiquetas de logs.
- **Responsabilidad Principal:** Recolectar logs desde el contenedor de la aplicaci√≥n y otros servicios.

### 2.4. Justificaci√≥n de la Configuraci√≥n Seleccionada

La elecci√≥n de esta configuraci√≥n se basa en la estabilidad y facilidad de configuraci√≥n comparada con las alternativas previamente consideradas:

- **Simplicidad en la Configuraci√≥n:** A diferencia de la pila ELK, la configuraci√≥n de Graylog junto con MongoDB y Elasticsearch simplifica la gesti√≥n de logs, evitando problemas complejos de vol√∫menes y permisos.
- **Eficiencia en el Monitoreo:** La integraci√≥n con Grafana y Loki permite una visualizaci√≥n y monitoreo eficiente de los logs y m√©tricas en tiempo real.
- **Escalabilidad y Flexibilidad:** La arquitectura modular facilita la escalabilidad y la adaptaci√≥n a futuras necesidades sin comprometer la estabilidad del sistema.
- **Facilidad de Uso:** La interfaz web intuitiva de Graylog y Grafana facilita la b√∫squeda, an√°lisis y visualizaci√≥n de los logs, mejorando la productividad del equipo de desarrollo y operaciones.

Esta configuraci√≥n garantiza una gesti√≥n de logs robusta y eficiente, superando las limitaciones encontradas con otras soluciones como la pila ELK, y proporcionando una base s√≥lida para el monitoreo y an√°lisis continuo de la infraestructura de contenedores.
![Contenedores Grafana y Loki](/docs/images/1.png)
![Visualizaci√≥n Grafana](/docs/images/3.png)


## üìã 3. Dockerfile del Contenedor de Aplicaci√≥n

A continuaci√≥n se presenta el **Dockerfile** del contenedor principal (App), donde se incluyen las dependencias, la l√≥gica de la aplicaci√≥n y las configuraciones esenciales:

FROM python:3.12-slim  
RUN apt-get update && apt-get install -y sqlite3 && apt-get clean  
WORKDIR /app  
COPY requirements.txt .  
RUN pip install --no-cache-dir -r requirements.txt  
COPY src/ ./src  
COPY Gestion_Penas.db ./Gestion_Penas.db  
EXPOSE 5000  
CMD ["python", "src/app.py"]

**Puntos Clave**:
- **Imagen base**: Versi√≥n ligera de Python para optimizar tiempos de construcci√≥n.  
- **Dependencias**: Instaladas a trav√©s de `requirements.txt`.  
- **Directorio de trabajo**: `/app`, para mantener la coherencia de los archivos.  
- **Ejecuci√≥n**: El proceso principal se inicia con `python src/app.py`.  

---



## üìã 4. Fichero de Composici√≥n (`docker-compose.yaml`)

A continuaci√≥n, se presenta un ejemplo de configuraci√≥n de **Docker Compose** para desplegar los contenedores necesarios: `app`, `db`, `grafana`, `loki` y `promtail`. Este archivo facilita la orquestaci√≥n y gesti√≥n de m√∫ltiples servicios en un entorno de contenedores.

```yaml
services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: app-container
    ports:
      - "5000:5000"
    user: "${UID}:${GID}"
    volumes:
      - ./src:/app/src
      - ./logs:/app/logs
    depends_on:
      - db
      - loki
      - promtail
    environment:
      DATABASE_URL: postgresql://user:password@db:5432/gestion_penas
    networks:
      - grafana_network
    
  db:
    image: postgres:15
    container_name: db-container
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: gestion_penas
    volumes:
      - ./Gestion_Penas.sql:/docker-entrypoint-initdb.d/Gestion_Penas.sql
    ports:
      - "5432:5432"
    networks:
      - grafana_network

  grafana:
    image: grafana/grafana-oss
    container_name: grafana
    restart: unless-stopped
    ports:
      - '3000:3000'
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - grafana_network

  loki:
    image: grafana/loki:2.9.0
    container_name: grafana-loki
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./loki-config.yaml:/etc/loki/local-config.yaml
    ports:
      - "3100:3100"
    networks:
      - grafana_network

  promtail:
    image: grafana/promtail:2.9.0
    container_name: promtail
    volumes:
      - ./logs:/var/log/nginx
      - ./promtail-config.yaml:/etc/promtail/config.yml
    command: -config.file=/etc/promtail/config.yml
    networks:
      - grafana_network

volumes:
  grafana_data:

networks:
  grafana_network:
    driver: bridge
```
### **Puntos Destacados**

#### **app (Contenedor de Aplicaci√≥n)**

- **Descripci√≥n:**  
  Contiene la aplicaci√≥n principal desarrollada en Python.

- **Caracter√≠sticas:**
  - **Construcci√≥n Personalizada:**  
    Utiliza un `Dockerfile` para construir la imagen desde el contexto actual.
  - **Puertos:**  
    Mapea el puerto `5000` del contenedor al host para acceder a la aplicaci√≥n.
  - **Vol√∫menes:**
    - Monta el directorio `./src` en `/app/src` para el c√≥digo fuente.
    - Monta el directorio `./logs` en `/app/logs` para almacenar los logs generados.
  - **Dependencias:**  
    Depende de los servicios `db`, `loki` y `promtail` para funcionar correctamente.
  - **Variables de Entorno:**  
    Configura la conexi√≥n a la base de datos mediante `DATABASE_URL`.
  - **Redes:**  
    Conectado a la red `grafana_network` para comunicarse con otros servicios.

#### **db (Contenedor de Base de Datos)**

- **Descripci√≥n:**  
  Base de datos PostgreSQL para almacenar la informaci√≥n estructurada de la aplicaci√≥n.

- **Caracter√≠sticas:**
  - **Imagen Oficial:**  
    Utiliza la imagen oficial de PostgreSQL versi√≥n `15`.
  - **Credenciales:**  
    Configura el usuario, contrase√±a y nombre de la base de datos a trav√©s de variables de entorno.
  - **Vol√∫menes:**
    - Monta el script `Gestion_Penas.sql` para inicializar la base de datos con las tablas y datos necesarios.
  - **Puertos:**  
    Expone el puerto `5432` para conexiones externas si es necesario.
  - **Redes:**  
    Conectado a la red `grafana_network`.

#### **grafana (Monitorizaci√≥n)**

- **Descripci√≥n:**  
  Herramienta de visualizaci√≥n para m√©tricas y logs, proporcionando dashboards interactivos.

- **Caracter√≠sticas:**
  - **Imagen Oficial:**  
    Utiliza la versi√≥n open-source de Grafana.
  - **Reinicio Autom√°tico:**  
    Configurado para reiniciarse autom√°ticamente a menos que se detenga manualmente.
  - **Puertos:**  
    Mapea el puerto `3000` para acceder a la interfaz web de Grafana.
  - **Vol√∫menes:**
    - Utiliza el volumen `grafana_data` para persistir la configuraci√≥n y los dashboards creados.
  - **Redes:**  
    Conectado a la red `grafana_network`.

#### **loki (Sistema de Logs)**

- **Descripci√≥n:**  
  Soluci√≥n ligera para la gesti√≥n y almacenamiento centralizado de logs.

- **Caracter√≠sticas:**
  - **Imagen Oficial:**  
    Utiliza la imagen de Loki versi√≥n `2.9.0`.
  - **Configuraci√≥n Personalizada:**  
    Monta un archivo de configuraci√≥n personalizado `loki-config.yaml`.
  - **Puertos:**  
    Expone el puerto `3100` para recibir logs.
  - **Redes:**  
    Conectado a la red `grafana_network`.

#### **promtail (Agente de Logs)**

- **Descripci√≥n:**  
  Agente encargado de recolectar y enviar logs a Loki.

- **Caracter√≠sticas:**
  - **Imagen Oficial:**  
    Utiliza la imagen de Promtail versi√≥n `2.9.0`.
  - **Configuraci√≥n Personalizada:**  
    Monta el archivo `promtail-config.yaml` para definir las fuentes y etiquetas de logs.
  - **Vol√∫menes:**
    - Monta el directorio `./logs` para recolectar los logs generados por la aplicaci√≥n.
  - **Redes:**  
    Conectado a la red `grafana_network`.

### **Consideraciones Adicionales**

- **Vol√∫menes Persistentes:**
  - **grafana_data:**  
    Asegura que los datos y configuraciones de Grafana persistan incluso si el contenedor se reinicia o elimina.

- **Redes:**
  - **grafana_network:**  
    Utiliza una red de tipo `bridge` para facilitar la comunicaci√≥n entre los diferentes servicios sin exponerlos innecesariamente al exterior.

### **Ventajas de esta Configuraci√≥n**

- **Orquestaci√≥n Simplificada:**  
  Docker Compose gestiona m√∫ltiples contenedores, facilitando el despliegue y la gesti√≥n de dependencias entre servicios.

- **Persistencia de Datos:**  
  Mediante el uso de vol√∫menes, se garantiza que los datos cr√≠ticos como logs y configuraciones se mantengan intactos entre reinicios.

- **Escalabilidad:**  
  La arquitectura modular permite a√±adir o eliminar servicios con facilidad seg√∫n las necesidades del proyecto.

- **Aislamiento de Servicios:**  
  Cada contenedor opera de manera independiente, reduciendo riesgos de conflictos y facilitando el mantenimiento.

- **Configuraciones Personalizadas:**  
  La posibilidad de montar archivos de configuraci√≥n personalizados (`loki-config.yaml`, `promtail-config.yaml`) permite adaptar cada servicio a requisitos espec√≠ficos.

---


## üìã 5. Implementaci√≥n y Validaci√≥n del Cl√∫ster

Para garantizar el correcto funcionamiento de los contenedores y su interacci√≥n, se han desarrollado pruebas automatizadas que validan tanto la disponibilidad de la aplicaci√≥n Flask como la conexi√≥n con la base de datos. A continuaci√≥n, se detalla c√≥mo se ha implementado este proceso utilizando **GitHub Actions** para automatizar el despliegue de los contenedores y la ejecuci√≥n de las pruebas de la API.

### **Despliegue Automatizado de Contenedores en GitHub Actions**

En el flujo de trabajo de **GitHub Actions**, se ha configurado un job que se encarga de desplegar los contenedores definidos en el archivo `docker-compose.yml`. Este job realiza las siguientes acciones:

1. **Clonar el Repositorio**:
    ```yaml
    - name: Clonar el repositorio
      uses: actions/checkout@v4
    ```
    *Descripci√≥n*: Utiliza la acci√≥n oficial de GitHub para clonar el c√≥digo fuente del repositorio.

2. **Instalar Docker y Docker Compose**:
    ```yaml
    - name: Instalar Docker
      run: |
        sudo apt-get update
        sudo apt-get install -y ca-certificates curl gnupg lsb-release
        curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
        echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
        sudo apt-get update
        sudo apt-get install -y docker-ce docker-ce-cli containerd.io
        docker --version

    - name: Instalar Docker Compose
      run: |
        sudo apt-get update
        sudo apt-get install -y docker-compose
        docker-compose --version
    ```
    *Descripci√≥n*: Instala Docker y Docker Compose en el runner de GitHub Actions, asegurando que las herramientas necesarias para contenerizar y gestionar los servicios est√©n disponibles.

3. **Iniciar y Habilitar el Servicio de Docker**:
    ```yaml
    - name: Iniciar Servicio de Docker
      run: |
        sudo systemctl start docker
        sudo systemctl enable docker
    ```
    *Descripci√≥n*: Inicia el servicio de Docker y lo habilita para que se inicie autom√°ticamente en futuras sesiones.

4. **Construir y Desplegar los Contenedores**:
    ```yaml
    - name: Construir im√°genes de Docker
      run: |
        docker-compose build --no-cache
      working-directory: './'

    - name: Iniciar Docker Compose
      run: docker-compose up -d
      working-directory: './'
    ```
    *Descripci√≥n*: Utiliza Docker Compose para construir las im√°genes de los servicios definidos en `docker-compose.yml` y los despliega en modo desacoplado (`-d`), permitiendo que se ejecuten en segundo plano.

### **Validaci√≥n del Funcionamiento del Cl√∫ster**

Una vez desplegados los contenedores, es crucial validar que todos los servicios est√°n operativos y se comunican correctamente. Para ello, se han implementado pruebas automatizadas que se ejecutan despu√©s de asegurar que los servicios est√°n activos.




1. **Configurar el Entorno Python**:
    ```yaml
    - name: Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
    ```
    *Descripci√≥n*: Configura el entorno Python con la versi√≥n especificada para ejecutar las pruebas.

2. **Cachear Dependencias de Pip**:
    ```yaml
    - name: Cachear dependencias de pip
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    ```
    *Descripci√≥n*: Utiliza la acci√≥n de cach√© de GitHub para almacenar y restaurar las dependencias de `pip`, acelerando el tiempo de instalaci√≥n en ejecuciones futuras.

3. **Instalar Dependencias**:
    ```yaml
    - name: Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        else
          pip install pytest requests
        fi
    ```
    *Descripci√≥n*: 
    - Actualiza `pip` a la √∫ltima versi√≥n.
    - Instala las dependencias listadas en `requirements.txt`. Si el archivo no existe, instala paquetes predeterminados como `pytest` y `requests`.

4. **Ejecutar Pruebas Automatizadas**:
    ```yaml
    - name: Ejecutar Pruebas
      run: |
        sudo chown -R $USER:$USER logs
        chmod 777 logs
        ls -l 
        pytest tests/*
    ```
    *Descripci√≥n*: Ejecuta las pruebas utilizando `pytest`, buscando en el directorio `tests/`. Estas pruebas validan:
    - **Disponibilidad de la Aplicaci√≥n Flask**: Comprueba que la API est√° en funcionamiento y responde a las solicitudes.
    - **Conexi√≥n con la Base de Datos**: Asegura que la aplicaci√≥n puede establecer una conexi√≥n exitosa con la base de datos configurada.
    - **Implicitamente comprueban la conexi√≥n entre los logs si no da error**



## üìã 6. Publicaci√≥n en GitHub Packages y Flujo CI/CD

En esta secci√≥n, se detalla c√≥mo se ha configurado **GitHub Actions** para automatizar la construcci√≥n y publicaci√≥n de im√°genes Docker en **GitHub Packages**, integrando los principios de **Integraci√≥n Continua** y **Despliegue Continuo** (CI/CD). Este proceso asegura la calidad y coherencia de la aplicaci√≥n mediante la ejecuci√≥n autom√°tica de pruebas y la publicaci√≥n de im√°genes solo si todas las pruebas son exitosas.

### **Descripci√≥n General del Flujo de Trabajo**

Cada vez que se realiza un _push_ a las ramas principales (`main` y `dev`), se activa un _pipeline_ que realiza las siguientes acciones:

1. **Construcci√≥n de la Imagen Docker**: Se construye la imagen Docker de la aplicaci√≥n utilizando el `Dockerfile` proporcionado.
2. **Ejecuci√≥n de Pruebas de Validaci√≥n**: Se ejecutan pruebas automatizadas para verificar que la aplicaci√≥n funciona correctamente.
3. **Publicaci√≥n de la Imagen en GitHub Packages**: Si todas las pruebas pasan exitosamente, la imagen Docker se publica en GitHub Packages, asegurando que solo se desplieguen im√°genes verificadas y de confianza.

### **Configuraci√≥n en `docker-publish.yml`**

El archivo `docker-publish.yml` contiene la configuraci√≥n necesaria para implementar este flujo de trabajo en **GitHub Actions**. A continuaci√≥n, se presenta el contenido del archivo con una explicaci√≥n de sus componentes principales.

```yaml
name: Build, Test, and Publish Docker Image 

on:
  push:
    branches:
      - main
      - dev

jobs:
  build-test-deploy:
    runs-on: ubuntu-latest

    env:
      IMAGE_NAME: ghcr.io/adrianoggm/cc.2024-2025.gestion-de-penas-de-futbol
      IMAGE_TAG: ${{ github.sha }}

    steps:
      # Clonar el repositorio
      - name: Clonar el repositorio
        uses: actions/checkout@v4

      # Instalar Docker
      - name: Instalar Docker
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            ca-certificates \
            curl \
            gnupg \
            lsb-release

          # Agregar la clave GPG oficial de Docker
          curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

          # Configurar el repositorio estable de Docker
          echo \
            "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
            $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

          sudo apt-get update
          sudo apt-get install -y docker-ce docker-ce-cli containerd.io

          # Verificar instalaci√≥n de Docker
          docker --version

      # Instalar Docker Compose usando apt-get
      - name: Instalar Docker Compose
        run: |
          sudo apt-get update
          sudo apt-get install -y docker-compose
          docker-compose --version

      # Iniciar y habilitar el servicio de Docker
      - name: Iniciar Servicio de Docker
        run: |
          sudo systemctl start docker
          sudo systemctl enable docker

      # Construir las im√°genes de Docker con 'docker-compose'
      - name: Construir im√°genes de Docker
        run: |
          docker-compose build --no-cache
        working-directory: './'

      # Iniciar Docker Compose en modo desacoplado
      - name: Iniciar Docker Compose
        run: docker-compose up -d
        working-directory: './'

      # Esperar 20 segundos para que los servicios se inicien
      - name: Esperar a que los servicios est√©n listos
        run: |
          echo "Esperando 20 segundos para que los servicios se inicien..."
          sleep 20
          echo "Tiempo de espera completado. Asumiendo que los servicios est√°n activos."
          docker-compose ps 
      # Configurar Python
      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      # Cachear dependencias de pip
      - name: Cachear dependencias de pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # Instalar dependencias
      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install pytest requests
          fi

      # Ejecutar Pruebas
      - name: Ejecutar Pruebas
        run: |
          sudo chown -R $USER:$USER logs
          chmod 777 logs
          ls -l 
          pytest 

      # Construir Imagen Docker
      - name: Construir Imagen Docker
        run: |
          docker build -t $IMAGE_NAME:$IMAGE_TAG .
          docker tag $IMAGE_NAME:$IMAGE_TAG $IMAGE_NAME:latest
        working-directory: './'

      # Iniciar Sesi√≥n en GitHub Container Registry
      - name: Iniciar Sesi√≥n en GitHub Container Registry
        run: echo ${{ secrets.GHCR_PASSWORD }} | docker login ghcr.io -u ${{ secrets.GHCR_USERNAME }} --password-stdin

      # Push de la Imagen Docker
      - name: Push de la Imagen Docker
        run: |
          docker push $IMAGE_NAME:$IMAGE_TAG
          docker push $IMAGE_NAME:latest

      # Desplegar y Limpiar Docker Compose
      - name: Desplegar y Limpiar Docker Compose
        if: always()
        run: docker-compose down
        working-directory: './'

```
---

### Componentes Clave del Flujo de Trabajo

#### Trigger del Flujo de Trabajo:

```yaml
on:
  push:
    branches:
      - main
      - dev
```
#### Variables de Entorno:
``` yaml
env:
  IMAGE_NAME: ghcr.io/adrianoggm/cc.2024-2025.gestion-de-penas-de-futbol
  IMAGE_TAG: ${{ github.sha }}

```
Descripci√≥n: Define las variables de entorno IMAGE_NAME y IMAGE_TAG que se utilizan para etiquetar las im√°genes Docker.
### Pasos del Flujo de Trabajo:
#### Clonar el Repositorio: Obtiene el c√≥digo fuente necesario para construir los contenedores.
```yaml
- name: Clonar el repositorio
  uses: actions/checkout@v4
```
#### Instalar Docker y Docker Compose: Prepara el entorno con las herramientas necesarias para manejar contenedores.
```yaml
- name: Instalar Docker
  run: |
    sudo apt-get update
    sudo apt-get install -y ...

- name: Instalar Docker Compose
  run: |
    sudo apt-get update
    sudo apt-get install -y docker-compose
    docker-compose --version
```
#### Iniciar el Servicio de Docker: Asegura que Docker est√° en funcionamiento.
```yaml
- name: Iniciar Servicio de Docker
  run: |
    sudo systemctl start docker
    sudo systemctl enable docker
  ```
#### Construir y Desplegar Contenedores: 
Utiliza Docker Compose para construir las im√°genes y desplegar los servicios.
```yaml

- name: Construir im√°genes de Docker
  run: |
    docker-compose build --no-cache
  working-directory: './'

- name: Iniciar Docker Compose
  run: docker-compose up -d
  working-directory: './'
```
#### Esperar y Verificar Servicios: Introduce una espera para permitir que los servicios se inicien y verifica su estado.
```yaml
- name: Esperar a que los servicios est√©n listos
  run: |
    echo "Esperando 20 segundos..."
    sleep 20
    echo "Tiempo de espera completado."
    docker-compose ps 
```
#### Configurar Python y Cachear Dependencias: Prepara el entorno Python y optimiza la instalaci√≥n de dependencias.
``` yaml

- name: Configurar Python
  uses: actions/setup-python@v4
  with:
    python-version: '3.12'

- name: Cachear dependencias de pip
  uses: actions/cache@v3
  with:
    path: ~/.cache/pip
    key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
    restore-keys: |
      ${{ runner.os }}-pip-
```
#### Instalar Dependencias: 
Actualiza pip y instala las dependencias necesarias para ejecutar las pruebas.
``` yaml
- name: Instalar dependencias
  run: |
    python -m pip install --upgrade pip
    if [ -f requirements.txt ]; then
      pip install -r requirements.txt
    else
      pip install pytest requests
  ```
#### Ejecutar Pruebas Automatizadas: 
Realiza pruebas automatizadas para validar el funcionamiento de la aplicaci√≥n.
``` yaml
- name: Ejecutar Pruebas
  run: |
    sudo chown -R $USER:$USER logs
    chmod 777 logs
    ls -l 
    pytest 
  ```
#### Construir y Publicar Imagen Docker: 
Construye la imagen final, la etiqueta y la publica en GitHub Container Registry.
``` yaml
- name: Construir Imagen Docker
  run: |
    docker build -t $IMAGE_NAME:$IMAGE_TAG .
    docker tag $IMAGE_NAME:$IMAGE_TAG $IMAGE_NAME:latest
  working-directory: './'

- name: Iniciar Sesi√≥n en GitHub Container Registry
  run: echo ${{ secrets.GHCR_PASSWORD }} | docker login ghcr.io -u ${{ secrets.GHCR_USERNAME }} --password-stdin

- name: Push de la Imagen Docker
  run: |
    docker push $IMAGE_NAME:$IMAGE_TAG
    docker push $IMAGE_NAME:latest
```
### Desplegar y Limpiar:
#### Detiene y elimina los contenedores desplegados, asegurando una limpieza adecuada.
```yaml
- name: Desplegar y Limpiar Docker Compose
  if: always()
  run: docker-compose down
  working-directory: './'
  ```
## Integraci√≥n de CI/CD

Este flujo de trabajo implementa los principios de **Integraci√≥n Continua** y **Despliegue Continuo** (CI/CD) al automatizar todo el proceso desde la construcci√≥n hasta la publicaci√≥n de las im√°genes Docker. Esto garantiza que cada cambio en el c√≥digo fuente se pruebe y despliegue de manera consistente y confiable, manteniendo altos est√°ndares de calidad y facilitando un desarrollo √°gil y eficiente.

### Beneficios de Esta Configuraci√≥n

- **Automatizaci√≥n Total**: Reduce la intervenci√≥n manual, minimizando errores y acelerando el proceso de despliegue.
- **Validaci√≥n Continua**: Asegura que cada push al repositorio pasa por un riguroso proceso de pruebas antes de ser desplegado.
- **Consistencia y Calidad**: Mantiene la coherencia en las versiones de las im√°genes y la calidad del c√≥digo mediante pruebas automatizadas.
- **Facilidad de Despliegue**: Simplifica el proceso de publicaci√≥n de im√°genes, permitiendo un despliegue r√°pido y seguro en diferentes entornos.

### Conclusi√≥n

La configuraci√≥n de **GitHub Actions** para la construcci√≥n y publicaci√≥n de im√°genes Docker en **GitHub Packages** es una parte esencial del flujo de trabajo de CI/CD, garantizando que la aplicaci√≥n se mantenga en un estado de alta calidad y est√© siempre lista para ser desplegada en producci√≥n. Esta automatizaci√≥n no solo mejora la eficiencia del desarrollo, sino que tambi√©n proporciona una capa adicional de confianza en la estabilidad y funcionalidad de la aplicaci√≥n.

**Nota** (se ha eliminado el yml anterior que probaba en el entorno local la aplicaci√≥n ya que eran pruebas redundantes que ya realiza este Action).